{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJKfDeXeriku"
      },
      "source": [
        "# Clasificación de semillas de trigo por medio redes neuronales usando Keras\n",
        "\n",
        "<div style=\"display: flex; justify-content: space-evenly; align-items: center;\">\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Vehn%C3%A4pelto_6.jpg/640px-Vehn%C3%A4pelto_6.jpg\" />\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/ae/Keras_logo.svg/480px-Keras_logo.svg.png\" width=\"300\" height=\"300\" />\n",
        "</div>\n",
        "\n",
        "Se creará una red neuronal para predecir la especie de una semilla de trigo basándonos en sus características. Usaremos el conjunto de datos de semillas de trigo de Instituto de Agrofísica de la Academia de Ciencias de Polonia en Lublin.\n",
        "\n",
        "Este conjunto de datos contiene 210 muestras de semillas de trigo de tres especies diferentes: Kama, Rosa y Canadian. \n",
        "\n",
        "Cada muestra tiene 7 características que serían las entradas de la red: área, perímetro, compactness, longitud del kernel, ancho del kernel, asimetría del kernel y longitud del grano del kernel. \n",
        "\n",
        "La especie de la semilla sería la salida de la red.\n",
        "\n",
        "Como herramienta se usará `Keras`, una librería de redes neuronales escrita en Python que corre sobre `TensorFlow`, dedicada a la experimentación rápida y fácil de redes neuronales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3jYztB5-rikv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoDp8dY_rikw"
      },
      "source": [
        "## Preparación de datos\n",
        "\n",
        "Primero se descargan los datos y se cargan en un `DataFrame` de `Pandas`, se le asigna un nombre a cada columna y se muestran los primeros 5 registros.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFq-1c_Frikw"
      },
      "source": [
        "### Descarga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "95wM8Y3Rrikw"
      },
      "outputs": [],
      "source": [
        "def download_csv_and_save(url, filename):\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    open(filename, 'wb').write(r.content)\n",
        "\n",
        "download_csv_and_save(\"https://cdn.discordapp.com/attachments/982420060457009235/1028508970513604719/seeds_dataset.csv\", \"seeds_dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJysYOVfrikw"
      },
      "source": [
        "### Nombre de las columnas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VwnneSHRrikw"
      },
      "outputs": [],
      "source": [
        "columns = [\"Area\", \"Perimeter\", \"Compatibility\", \"Core length\", \"Core width\", \"Asymmetry coefficient\", \"Grain furrow length\", \"Label\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L44YYimdrikw"
      },
      "source": [
        "### Lectura de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AaXE2Msurikx",
        "outputId": "04443cb0-bab8-4825-c241-51adf453b169"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>Perimeter</th>\n",
              "      <th>Compatibility</th>\n",
              "      <th>Core length</th>\n",
              "      <th>Core width</th>\n",
              "      <th>Asymmetry coefficient</th>\n",
              "      <th>Grain furrow length</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.26</td>\n",
              "      <td>14.84</td>\n",
              "      <td>0.8710</td>\n",
              "      <td>5.763</td>\n",
              "      <td>3.312</td>\n",
              "      <td>2.221</td>\n",
              "      <td>5.220</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14.88</td>\n",
              "      <td>14.57</td>\n",
              "      <td>0.8811</td>\n",
              "      <td>5.554</td>\n",
              "      <td>3.333</td>\n",
              "      <td>1.018</td>\n",
              "      <td>4.956</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14.29</td>\n",
              "      <td>14.09</td>\n",
              "      <td>0.9050</td>\n",
              "      <td>5.291</td>\n",
              "      <td>3.337</td>\n",
              "      <td>2.699</td>\n",
              "      <td>4.825</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13.84</td>\n",
              "      <td>13.94</td>\n",
              "      <td>0.8955</td>\n",
              "      <td>5.324</td>\n",
              "      <td>3.379</td>\n",
              "      <td>2.259</td>\n",
              "      <td>4.805</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16.14</td>\n",
              "      <td>14.99</td>\n",
              "      <td>0.9034</td>\n",
              "      <td>5.658</td>\n",
              "      <td>3.562</td>\n",
              "      <td>1.355</td>\n",
              "      <td>5.175</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Area  Perimeter  Compatibility  Core length  Core width  \\\n",
              "0  15.26      14.84         0.8710        5.763       3.312   \n",
              "1  14.88      14.57         0.8811        5.554       3.333   \n",
              "2  14.29      14.09         0.9050        5.291       3.337   \n",
              "3  13.84      13.94         0.8955        5.324       3.379   \n",
              "4  16.14      14.99         0.9034        5.658       3.562   \n",
              "\n",
              "   Asymmetry coefficient  Grain furrow length  Label  \n",
              "0                  2.221                5.220      1  \n",
              "1                  1.018                4.956      1  \n",
              "2                  2.699                4.825      1  \n",
              "3                  2.259                4.805      1  \n",
              "4                  1.355                5.175      1  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"seeds_dataset.csv\", header=None, names=columns)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSRE20vcrikx"
      },
      "source": [
        "### Normalización de datos\n",
        "\n",
        "Se usa la función `MinMaxScaler` de `sklearn` para normalizar los datos de entrada entre 0 y 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "O-e0nWlXrikx"
      },
      "outputs": [],
      "source": [
        "def normalize_data(data):\n",
        "    \"\"\"Normalizes the data between 0 and 1\"\"\"\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    data = min_max_scaler.fit_transform(data)\n",
        "    return pd.DataFrame(data, columns=columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGgkyzEQriky"
      },
      "source": [
        "### División de las entradas y salidas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "csCzjlAdriky"
      },
      "outputs": [],
      "source": [
        "def split_features_and_labels(df):\n",
        "    \"\"\"Splits the features and labels\"\"\"\n",
        "    features = df.drop(\"Label\", axis=1, inplace=False)\n",
        "    labels = df[\"Label\"]\n",
        "    return features, labels\n",
        "\n",
        "features, labels = split_features_and_labels(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJyn6wl-riky"
      },
      "source": [
        "### Conversión de las salidas a one-hot encoding\n",
        "\n",
        "Ya que las salidas son categóricas, se usa la función `to_categorical` de `keras.utils` para convertirlas a one-hot encoding. Esta técnica consiste en convertir una variable categórica en un vector de 0s y 1s. Por ejemplo, si tenemos 3 categorías, la categoría 1 se convertiría en `[1, 0, 0]`, la categoría 2 en `[0, 1, 0]` y la categoría 3 en `[0, 0, 1]`.\n",
        "\n",
        "**Nota**: en este proceso tuvimos un problema: al usar esta función, nos regresó 4 columnas en lugar de 3. Esto se debe a que la función `to_categorical` toma como entrada el número de categorías, y como tenemos 3 categorías, la función pensó que la categoría 0 no existía. \n",
        "\n",
        "Para solucionar esto, se eliminó la primera columna de la matriz de salidas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PW_QWPK6riky"
      },
      "outputs": [],
      "source": [
        "labels = to_categorical(labels.values)\n",
        "labels = pd.DataFrame(labels, columns=[\"?\", \"Kama\", \"Rosa\", \"Canadian\"])\n",
        "labels = labels.drop(\"?\", axis=1, inplace=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRb7mTRvriky"
      },
      "source": [
        "### División de los datos en entrenamiento y prueba\n",
        "\n",
        "Se usó la función `train_test_split` de `sklearn` para dividir los datos en 2 conjuntos: entrenamiento y prueba. El conjunto de entrenamiento se usará para entrenar la red neuronal, y el conjunto de prueba se usará para evaluar el desempeño de la red.\n",
        "\n",
        "Igualmente se especificó que el 70% de los datos se usará para entrenamiento y el 30% para prueba. Además que se especificó que los datos se dividieran de forma aleatoria, ya que inicialmente el conjunto de datos está ordenado por especie.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "U-wr234crikz"
      },
      "outputs": [],
      "source": [
        "train, test, train_labels, test_labels = train_test_split(features, labels,  shuffle=True, train_size=0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXINShBirikz"
      },
      "source": [
        "Al hacer la división de los datos, los indices de las filas se mezclaron, por lo que se tuvo que reordenar los datos de entrada y salida para que coincidieran."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4TWTvjeJrikz"
      },
      "outputs": [],
      "source": [
        "test.index = test_labels.index = np.arange(0, len(test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66oH8G3zrikz"
      },
      "source": [
        "## Creación y entrenamiento de la red neuronal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA7HrYphrikz"
      },
      "source": [
        "### Creación del modelo\n",
        "\n",
        "Se creó un modelo secuencial, que es una pila lineal de capas. La configuración inicial que se pensó fue la siguiente:\n",
        "\n",
        "- Capa de entrada con 64 neuronas, cada una conectada al input de 7 características. Se usa la función de activación `relu` para las neuronas de la capa de entrada.\n",
        "- Capa oculta con 32 neuronas. También se usa la función de activación `relu`.\n",
        "- Capa de salida con 3 neuronas, una por cada categoría. Se usa la función de activación `softmax` para la capa de salida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XdXJ2lYrikz"
      },
      "source": [
        "La función de activación `relu` es posiblemente la más usada en capas ocultas. Se usa para evitar que los valores de las neuronas se vuelvan negativos, lo que podría causar problemas en la red.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://149695847.v2.pressablecdn.com/wp-content/uploads/2021/11/ReLU-activation-function.png\" />\n",
        "</p>\n",
        "\n",
        "La función de activación `softmax` es una función de activación que se usa para clasificación. Su función es convertir los valores de las neuronas de la capa de salida en probabilidades. Por ejemplo, si tenemos 3 categorías, la neurona 1 tendrá una probabilidad de que la semilla sea de la categoría 1, la neurona 2 tendrá una probabilidad de que la semilla sea de la categoría 2 y la neurona 3 tendrá una probabilidad de que la semilla sea de la categoría 3.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.researchgate.net/publication/319121953/figure/fig2/AS:527474636398592@1502771161390/Softmax-activation-function.png\" />\n",
        "  </p> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6BXwivj6rik0"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation=tf.nn.relu, input_shape=(7,)),\n",
        "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwigabwdrik0"
      },
      "source": [
        "### Compilación del modelo\n",
        "\n",
        "Se compiló el modelo con la función `compile` de `keras`. Se especificó que se usaría la función de pérdida o error `categorical_crossentropy`, que es una función de pérdida que se usa para clasificación. También se especificó que se usaría el optimizador `adam`.\n",
        "\n",
        "Los optimizadores son funciones que implementan los algoritmos de `backpropagation` y `gradient descent` para entrenar la red neuronal.\n",
        "\n",
        "Hay diferentes tipos de optimizadores, y cada uno tiene sus ventajas y desventajas. El optimizador `adam` es uno de los más usados, y es el que se usó en este proyecto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "E7L6RNL5rik0"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(), loss=tf.losses.CategoricalCrossentropy(), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPo48UMprik0"
      },
      "source": [
        "### Entrenamiento del modelo\n",
        "\n",
        "Se entrenó el modelo con la función `fit` de `keras`. Se especificó que se usarían 50 épocas, que es el número de veces que se entrenará la red con el conjunto de entrenamiento. También se especificó que se usaría un tamaño de lote de 10, que es el número de muestras que se usarán para entrenar la red en cada época. Estos lotes se llaman `mini-batches` y es una técnica usada para optimizar el entrenamiento de la red."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF_qkRZCrik0",
        "outputId": "3bda514d-1f14-47a6-f107-eb7ffe8c1f88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 120ms/step - loss: 1.3202 - accuracy: 0.3605 - val_loss: 1.1547 - val_accuracy: 0.4286\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.1450 - accuracy: 0.4014 - val_loss: 1.0871 - val_accuracy: 0.3175\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.9677 - accuracy: 0.5510 - val_loss: 0.9335 - val_accuracy: 0.5397\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8887 - accuracy: 0.5102 - val_loss: 0.8326 - val_accuracy: 0.6825\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.8011 - accuracy: 0.8095 - val_loss: 0.7717 - val_accuracy: 0.8254\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.7413 - accuracy: 0.8571 - val_loss: 0.7521 - val_accuracy: 0.7460\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7181 - accuracy: 0.8163 - val_loss: 0.7308 - val_accuracy: 0.7302\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6907 - accuracy: 0.8435 - val_loss: 0.7000 - val_accuracy: 0.8254\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.6689 - accuracy: 0.8844 - val_loss: 0.6657 - val_accuracy: 0.8571\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6482 - accuracy: 0.9048 - val_loss: 0.6478 - val_accuracy: 0.9048\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6306 - accuracy: 0.9320 - val_loss: 0.6357 - val_accuracy: 0.8730\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6115 - accuracy: 0.8707 - val_loss: 0.6343 - val_accuracy: 0.7460\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5967 - accuracy: 0.8844 - val_loss: 0.6095 - val_accuracy: 0.8254\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5807 - accuracy: 0.9048 - val_loss: 0.5872 - val_accuracy: 0.8730\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5661 - accuracy: 0.8980 - val_loss: 0.5793 - val_accuracy: 0.8571\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5509 - accuracy: 0.8980 - val_loss: 0.5679 - val_accuracy: 0.8413\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5353 - accuracy: 0.8912 - val_loss: 0.5579 - val_accuracy: 0.8571\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5261 - accuracy: 0.8776 - val_loss: 0.5493 - val_accuracy: 0.8413\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5165 - accuracy: 0.8980 - val_loss: 0.5245 - val_accuracy: 0.9048\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5068 - accuracy: 0.9184 - val_loss: 0.5132 - val_accuracy: 0.9048\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4889 - accuracy: 0.8980 - val_loss: 0.5263 - val_accuracy: 0.8095\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4818 - accuracy: 0.8776 - val_loss: 0.5113 - val_accuracy: 0.8571\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4732 - accuracy: 0.8912 - val_loss: 0.4971 - val_accuracy: 0.8571\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4605 - accuracy: 0.8912 - val_loss: 0.4843 - val_accuracy: 0.8889\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4521 - accuracy: 0.8844 - val_loss: 0.4753 - val_accuracy: 0.8889\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4469 - accuracy: 0.9388 - val_loss: 0.4685 - val_accuracy: 0.8889\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4323 - accuracy: 0.9048 - val_loss: 0.4674 - val_accuracy: 0.9048\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4305 - accuracy: 0.8912 - val_loss: 0.4672 - val_accuracy: 0.8413\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4196 - accuracy: 0.8844 - val_loss: 0.4568 - val_accuracy: 0.8571\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4121 - accuracy: 0.8980 - val_loss: 0.4479 - val_accuracy: 0.8730\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4047 - accuracy: 0.9048 - val_loss: 0.4347 - val_accuracy: 0.8889\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3967 - accuracy: 0.9116 - val_loss: 0.4286 - val_accuracy: 0.8889\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3940 - accuracy: 0.9116 - val_loss: 0.4291 - val_accuracy: 0.8571\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3864 - accuracy: 0.9116 - val_loss: 0.4210 - val_accuracy: 0.8889\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3803 - accuracy: 0.9184 - val_loss: 0.4220 - val_accuracy: 0.8571\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3709 - accuracy: 0.9184 - val_loss: 0.4100 - val_accuracy: 0.8889\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3672 - accuracy: 0.9116 - val_loss: 0.3986 - val_accuracy: 0.8889\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3591 - accuracy: 0.9184 - val_loss: 0.3998 - val_accuracy: 0.8889\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3608 - accuracy: 0.9184 - val_loss: 0.3905 - val_accuracy: 0.8889\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3509 - accuracy: 0.9048 - val_loss: 0.4016 - val_accuracy: 0.9048\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3488 - accuracy: 0.8912 - val_loss: 0.4136 - val_accuracy: 0.8413\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3488 - accuracy: 0.9048 - val_loss: 0.3752 - val_accuracy: 0.9048\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3460 - accuracy: 0.9184 - val_loss: 0.3650 - val_accuracy: 0.9048\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3372 - accuracy: 0.9252 - val_loss: 0.3798 - val_accuracy: 0.9048\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3275 - accuracy: 0.8980 - val_loss: 0.4101 - val_accuracy: 0.8095\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3357 - accuracy: 0.8912 - val_loss: 0.3649 - val_accuracy: 0.8889\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3192 - accuracy: 0.9184 - val_loss: 0.3589 - val_accuracy: 0.9048\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3156 - accuracy: 0.9184 - val_loss: 0.3578 - val_accuracy: 0.8889\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3143 - accuracy: 0.9184 - val_loss: 0.3508 - val_accuracy: 0.8889\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3081 - accuracy: 0.9388 - val_loss: 0.3458 - val_accuracy: 0.9048\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train, train_labels, epochs=50, batch_size=32, validation_data=(test, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RINOtWXlrik0"
      },
      "source": [
        "## Evaluación del modelo\n",
        "\n",
        "Aquí se evalúa el desempeño de la red neuronal. Se usa la función `evaluate` de `keras` para evaluar el modelo con el conjunto de prueba. Esta función regresa el valor de la función de pérdida y la precisión del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrbI03x8rik1",
        "outputId": "229698aa-3b02-4979-c4ad-88fb8d2b0fc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.9048\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq1WICIcrik1"
      },
      "source": [
        "## Predicción\n",
        "\n",
        "Se usó la función `predict` de `keras` para predecir la categoría de una semilla. Para facilidar este trabajo, se definió una función que recibe como parámetros las características de la semilla y regresa la categoría a la que pertenece."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "S6bo_oxZrik1"
      },
      "outputs": [],
      "source": [
        "def predict(*indices):\n",
        "    \"\"\"Predicts the label of a given index\"\"\"\n",
        "    class_names = [\"Kama\", \"Rosa\", \"Canadian\"]\n",
        "    for index in indices:\n",
        "        prediction = model.predict(test.loc[index:index].values.reshape(1, 7))\n",
        "        print(\"Prediction: \", class_names[np.argmax(prediction)], \" | Actual: \", class_names[np.argmax(test_labels.loc[index].values)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAcjSHChrik1"
      },
      "source": [
        "Se usó la semilla 1 del conjunto de prueba para hacer la predicción. La función regresa un vector de 3 elementos, cada uno con una probabilidad de que la semilla sea de la categoría 1, 2 o 3. La categoría con la probabilidad más alta es la categoría de la semilla."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imMqVdv4rik1"
      },
      "source": [
        "Se puede ver que para la semilla 1, su categoría esperada es Rosa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz3HVEXIrik1",
        "outputId": "3e329d9c-03cd-4fb9-8c02-a27f42c8d53e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Kama        0.0\n",
              "Rosa        1.0\n",
              "Canadian    0.0\n",
              "Name: 0, dtype: float32"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_labels.loc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOuqJofQrik2"
      },
      "source": [
        "Al iniciar la predicción, se puede ver que la categoría predicha es Rosa, lo que significa que la red neuronal predijo correctamente la categoría de la semilla."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B7WAa2krik2",
        "outputId": "23d23039-146c-494b-e827-e5fd58d6be3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 145ms/step\n",
            "Prediction:  Kama  | Actual:  Canadian\n"
          ]
        }
      ],
      "source": [
        "predict(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IapTqQxlrik2"
      },
      "source": [
        "También podemos predecir los primeros 10 elementos del conjunto de prueba. Se puede ver que la red neuronal predijo correctamente todas las categorías."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahxSzQnGrik2",
        "outputId": "44e03897-4e88-4588-a009-0de5111de84b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 36ms/step\n",
            "Prediction:  Rosa  | Actual:  Rosa\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Prediction:  Kama  | Actual:  Canadian\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Prediction:  Canadian  | Actual:  Canadian\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Prediction:  Rosa  | Actual:  Rosa\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Prediction:  Canadian  | Actual:  Canadian\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Prediction:  Kama  | Actual:  Kama\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Prediction:  Rosa  | Actual:  Rosa\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Prediction:  Rosa  | Actual:  Rosa\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Prediction:  Canadian  | Actual:  Canadian\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Prediction:  Canadian  | Actual:  Canadian\n"
          ]
        }
      ],
      "source": [
        "predict(*range(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FID7_wmurik2"
      },
      "source": [
        "### Predicciones totales\n",
        "\n",
        "Aunque podemos ver que la red neuronal no predijo correctamente todas las categorías, se puede ver que la precisión del modelo en promedio es de 0.95, lo que significa que el modelo predijo correctamente el 95% de las categorías."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WppuIt6Qrik2",
        "outputId": "8b1f2292-6f6d-4bee-8111-2ce4a528adfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 0s/step\n",
            "Predicciones en la categoría Kama:  20\n",
            "Predicciones en la categoría Rosa:  21\n",
            "Predicciones en la categoría Canadian:  22\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(test)\n",
        "\n",
        "print(\"Predicciones en la categoría Kama: \", len(list(filter(lambda x: np.argmax(x) == 0, predictions))))\n",
        "print(\"Predicciones en la categoría Rosa: \", len(list(filter(lambda x: np.argmax(x) == 1, predictions))))\n",
        "print(\"Predicciones en la categoría Canadian: \", len(list(filter(lambda x: np.argmax(x) == 2, predictions))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ2AwIjfrik2",
        "outputId": "0e4cddb4-829f-461d-e931-3fcca8d9d67a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cantidad de datos en el conjunto de test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Kama</th>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rosa</th>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Canadian</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Cantidad de datos en el conjunto de test\n",
              "Kama                                            22\n",
              "Rosa                                            21\n",
              "Canadian                                        20"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(test_labels.value_counts().values, index=[\"Kama\", \"Rosa\", \"Canadian\"], columns=[\"Cantidad de datos en el conjunto de test\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjfrwpI_rik3"
      },
      "source": [
        "## Gráficas de de error y precisión\n",
        "\n",
        "Aquí se muestran las gráficas de error y precisión del modelo. Se puede ver que el error disminuye a medida que aumenta el número de épocas, lo que significa que el modelo se está entrenando correctamente. También se puede ver que la precisión aumenta, lo que significa que el modelo está aprendiendo correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7REIqiirik3"
      },
      "source": [
        "### Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzKzN0ttrik3",
        "outputId": "b4f46a38-e903-4c84-a9d0-6ada961c52b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x23c5e50daf0>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.subplot(211)\n",
        "plt.title('Loss')\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhr0s278rik3"
      },
      "source": [
        "### Precisión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfdKv4J_rik3",
        "outputId": "af3a051b-c083-4ad7-f08f-5ba55a11a05a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x23c613c0c70>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.subplot(212)\n",
        "plt.title('Accuracy')\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='test')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "144PYaOnrik3"
      },
      "source": [
        "# Clasificación de semillas usando una arquitectura 7:12:8:1\n",
        "\n",
        "Ya que el procesamiento de datos usado en el ejercicio anterior fue dirigido a una salida de 3 categorias, no podemos usarlo para una capa de salida de una sola neurona. Por ende, se debe realizar un nuevo procesamiento de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalización de datos\n",
        "\n",
        "Se normalizaron los datos para que todos los valores estén entre 0 y 1. Esto se hizo para que el modelo pueda entrenarse más rápido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "I7N3H6KBrik4"
      },
      "outputs": [],
      "source": [
        "normalized_df = normalize_data(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## División de entradas y salidas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "StWW9CId609f"
      },
      "outputs": [],
      "source": [
        "features, labels = split_features_and_labels(normalized_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## División de datos de entrenamiento y prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2SI2ldpn8os1"
      },
      "outputs": [],
      "source": [
        "train, test, train_labels, test_labels = train_test_split(features, labels,  shuffle=True, train_size=0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Igualmente que en el ejercicio anterior, se reinician los indices de los datos de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "l2nRA62m1PsW"
      },
      "outputs": [],
      "source": [
        "test.index = test_labels.index = np.arange(0, len(test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A diferencia del ejercicio anterior, no se procesarán las salidas de la misma manera. En este caso, se usará una capa de salida de una sola neurona, por lo que se debe convertir la salida a un valor entre 0 y 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creación del modelo\n",
        "\n",
        "Se creó el modelo con la función `Sequential` de `keras`. Se agregaron 4 capas, una capa de entrada, dos capas ocultas y una capa de salida. La capa de entrada tiene 7 neuronas, la primera capa oculta tiene 12 neuronas, la segunda capa oculta tiene 8 neuronas y la capa de salida tiene 1 neurona.\n",
        "\n",
        "Las tres primeras capas usan la función de activación `relu`, y la capa de salida usa la función de activación `sigmoid`.\n",
        "\n",
        "En la última no usamos la función de activación `softmax` porque la salida es un valor entre 0 y 1, y no una probabilidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "TvqSDwws8vp0"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(7, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(12, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(8, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al compilar el modelo, se usa el mismo optimizador `adam` y la misma métrica `accuracy` que en el ejercicio anterior. Pero en este caso, se usa la función de pérdida `MeanAbsoluteError`, que es una función de pérdida que se usa para regresión. Se tuvo duda acerca de si usar `MeanSquaredError` o `MeanAbsoluteError`, pero se decidió usar `MeanAbsoluteError` porque es la función que nos dió menor error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nyNcEU_W9MJU"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.MeanAbsoluteError(), metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Entrenamos y evaluamos el modelo de la misma manera que en el ejercicio anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1gS-whA96V8",
        "outputId": "d928aca7-8959-465c-e147-6948b3522631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "5/5 [==============================] - 1s 68ms/step - loss: 0.3232 - accuracy: 0.3197 - val_loss: 0.3592 - val_accuracy: 0.3651\n",
            "Epoch 2/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3155 - accuracy: 0.3537 - val_loss: 0.3529 - val_accuracy: 0.5238\n",
            "Epoch 3/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3084 - accuracy: 0.4966 - val_loss: 0.3473 - val_accuracy: 0.6667\n",
            "Epoch 4/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3035 - accuracy: 0.5646 - val_loss: 0.3446 - val_accuracy: 0.6667\n",
            "Epoch 5/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3016 - accuracy: 0.5714 - val_loss: 0.3424 - val_accuracy: 0.6667\n",
            "Epoch 6/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2999 - accuracy: 0.5646 - val_loss: 0.3399 - val_accuracy: 0.6667\n",
            "Epoch 7/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2974 - accuracy: 0.5510 - val_loss: 0.3372 - val_accuracy: 0.6667\n",
            "Epoch 8/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2948 - accuracy: 0.5442 - val_loss: 0.3346 - val_accuracy: 0.6667\n",
            "Epoch 9/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2923 - accuracy: 0.5306 - val_loss: 0.3318 - val_accuracy: 0.6667\n",
            "Epoch 10/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2895 - accuracy: 0.5238 - val_loss: 0.3289 - val_accuracy: 0.6667\n",
            "Epoch 11/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2865 - accuracy: 0.5238 - val_loss: 0.3256 - val_accuracy: 0.6667\n",
            "Epoch 12/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2834 - accuracy: 0.5238 - val_loss: 0.3222 - val_accuracy: 0.6667\n",
            "Epoch 13/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2802 - accuracy: 0.5238 - val_loss: 0.3186 - val_accuracy: 0.6667\n",
            "Epoch 14/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2768 - accuracy: 0.5306 - val_loss: 0.3150 - val_accuracy: 0.6667\n",
            "Epoch 15/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2733 - accuracy: 0.5510 - val_loss: 0.3113 - val_accuracy: 0.6667\n",
            "Epoch 16/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2699 - accuracy: 0.5510 - val_loss: 0.3077 - val_accuracy: 0.6825\n",
            "Epoch 17/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2666 - accuracy: 0.5510 - val_loss: 0.3037 - val_accuracy: 0.6667\n",
            "Epoch 18/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2630 - accuracy: 0.5510 - val_loss: 0.2996 - val_accuracy: 0.6825\n",
            "Epoch 19/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2594 - accuracy: 0.5510 - val_loss: 0.2957 - val_accuracy: 0.6825\n",
            "Epoch 20/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2561 - accuracy: 0.5578 - val_loss: 0.2917 - val_accuracy: 0.6825\n",
            "Epoch 21/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2525 - accuracy: 0.5578 - val_loss: 0.2880 - val_accuracy: 0.6825\n",
            "Epoch 22/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2495 - accuracy: 0.5578 - val_loss: 0.2844 - val_accuracy: 0.6825\n",
            "Epoch 23/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2456 - accuracy: 0.5578 - val_loss: 0.2813 - val_accuracy: 0.6825\n",
            "Epoch 24/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2424 - accuracy: 0.5510 - val_loss: 0.2777 - val_accuracy: 0.6667\n",
            "Epoch 25/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2390 - accuracy: 0.5578 - val_loss: 0.2739 - val_accuracy: 0.6667\n",
            "Epoch 26/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2357 - accuracy: 0.5510 - val_loss: 0.2700 - val_accuracy: 0.6825\n",
            "Epoch 27/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2324 - accuracy: 0.5578 - val_loss: 0.2661 - val_accuracy: 0.6667\n",
            "Epoch 28/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2289 - accuracy: 0.5578 - val_loss: 0.2624 - val_accuracy: 0.6667\n",
            "Epoch 29/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2255 - accuracy: 0.5578 - val_loss: 0.2592 - val_accuracy: 0.6667\n",
            "Epoch 30/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2225 - accuracy: 0.5578 - val_loss: 0.2556 - val_accuracy: 0.6667\n",
            "Epoch 31/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2192 - accuracy: 0.5646 - val_loss: 0.2522 - val_accuracy: 0.6667\n",
            "Epoch 32/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2162 - accuracy: 0.5646 - val_loss: 0.2488 - val_accuracy: 0.6825\n",
            "Epoch 33/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2132 - accuracy: 0.5714 - val_loss: 0.2456 - val_accuracy: 0.6825\n",
            "Epoch 34/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2100 - accuracy: 0.5714 - val_loss: 0.2431 - val_accuracy: 0.6825\n",
            "Epoch 35/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2071 - accuracy: 0.5714 - val_loss: 0.2400 - val_accuracy: 0.6825\n",
            "Epoch 36/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2040 - accuracy: 0.5714 - val_loss: 0.2367 - val_accuracy: 0.6825\n",
            "Epoch 37/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2010 - accuracy: 0.5714 - val_loss: 0.2338 - val_accuracy: 0.6825\n",
            "Epoch 38/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1983 - accuracy: 0.5850 - val_loss: 0.2307 - val_accuracy: 0.6825\n",
            "Epoch 39/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1952 - accuracy: 0.5850 - val_loss: 0.2272 - val_accuracy: 0.6825\n",
            "Epoch 40/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1930 - accuracy: 0.5850 - val_loss: 0.2243 - val_accuracy: 0.6825\n",
            "Epoch 41/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1898 - accuracy: 0.5918 - val_loss: 0.2213 - val_accuracy: 0.6825\n",
            "Epoch 42/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1870 - accuracy: 0.5986 - val_loss: 0.2184 - val_accuracy: 0.6825\n",
            "Epoch 43/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1840 - accuracy: 0.5986 - val_loss: 0.2163 - val_accuracy: 0.6825\n",
            "Epoch 44/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1815 - accuracy: 0.5986 - val_loss: 0.2128 - val_accuracy: 0.6825\n",
            "Epoch 45/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1783 - accuracy: 0.5986 - val_loss: 0.2092 - val_accuracy: 0.6825\n",
            "Epoch 46/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1756 - accuracy: 0.5986 - val_loss: 0.2062 - val_accuracy: 0.6825\n",
            "Epoch 47/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1728 - accuracy: 0.5986 - val_loss: 0.2028 - val_accuracy: 0.6825\n",
            "Epoch 48/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1699 - accuracy: 0.5986 - val_loss: 0.2007 - val_accuracy: 0.6825\n",
            "Epoch 49/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1675 - accuracy: 0.5918 - val_loss: 0.1966 - val_accuracy: 0.6825\n",
            "Epoch 50/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1644 - accuracy: 0.5986 - val_loss: 0.1936 - val_accuracy: 0.6825\n",
            "Epoch 51/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1614 - accuracy: 0.5986 - val_loss: 0.1903 - val_accuracy: 0.6825\n",
            "Epoch 52/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1591 - accuracy: 0.5918 - val_loss: 0.1874 - val_accuracy: 0.6667\n",
            "Epoch 53/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1557 - accuracy: 0.5986 - val_loss: 0.1852 - val_accuracy: 0.6667\n",
            "Epoch 54/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1529 - accuracy: 0.5986 - val_loss: 0.1823 - val_accuracy: 0.6667\n",
            "Epoch 55/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1503 - accuracy: 0.5986 - val_loss: 0.1790 - val_accuracy: 0.6667\n",
            "Epoch 56/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1478 - accuracy: 0.5986 - val_loss: 0.1765 - val_accuracy: 0.6667\n",
            "Epoch 57/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1450 - accuracy: 0.5986 - val_loss: 0.1741 - val_accuracy: 0.6667\n",
            "Epoch 58/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1420 - accuracy: 0.5986 - val_loss: 0.1697 - val_accuracy: 0.6667\n",
            "Epoch 59/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1396 - accuracy: 0.5986 - val_loss: 0.1669 - val_accuracy: 0.6667\n",
            "Epoch 60/500\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.1376 - accuracy: 0.5986 - val_loss: 0.1643 - val_accuracy: 0.6667\n",
            "Epoch 61/500\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1351 - accuracy: 0.5986 - val_loss: 0.1624 - val_accuracy: 0.6667\n",
            "Epoch 62/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1330 - accuracy: 0.5986 - val_loss: 0.1599 - val_accuracy: 0.6667\n",
            "Epoch 63/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1302 - accuracy: 0.6054 - val_loss: 0.1570 - val_accuracy: 0.6667\n",
            "Epoch 64/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1285 - accuracy: 0.6054 - val_loss: 0.1549 - val_accuracy: 0.6667\n",
            "Epoch 65/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1261 - accuracy: 0.6054 - val_loss: 0.1542 - val_accuracy: 0.6667\n",
            "Epoch 66/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1245 - accuracy: 0.6054 - val_loss: 0.1515 - val_accuracy: 0.6667\n",
            "Epoch 67/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1221 - accuracy: 0.6054 - val_loss: 0.1482 - val_accuracy: 0.6667\n",
            "Epoch 68/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1205 - accuracy: 0.6054 - val_loss: 0.1461 - val_accuracy: 0.6667\n",
            "Epoch 69/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1184 - accuracy: 0.6054 - val_loss: 0.1447 - val_accuracy: 0.6667\n",
            "Epoch 70/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1165 - accuracy: 0.6122 - val_loss: 0.1433 - val_accuracy: 0.6667\n",
            "Epoch 71/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1148 - accuracy: 0.6122 - val_loss: 0.1417 - val_accuracy: 0.6667\n",
            "Epoch 72/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1133 - accuracy: 0.6122 - val_loss: 0.1396 - val_accuracy: 0.6667\n",
            "Epoch 73/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1119 - accuracy: 0.6122 - val_loss: 0.1383 - val_accuracy: 0.6667\n",
            "Epoch 74/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1104 - accuracy: 0.6122 - val_loss: 0.1362 - val_accuracy: 0.6667\n",
            "Epoch 75/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1087 - accuracy: 0.6122 - val_loss: 0.1350 - val_accuracy: 0.6667\n",
            "Epoch 76/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1082 - accuracy: 0.6054 - val_loss: 0.1345 - val_accuracy: 0.6667\n",
            "Epoch 77/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1055 - accuracy: 0.6122 - val_loss: 0.1320 - val_accuracy: 0.6667\n",
            "Epoch 78/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1047 - accuracy: 0.6054 - val_loss: 0.1310 - val_accuracy: 0.6667\n",
            "Epoch 79/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1030 - accuracy: 0.6054 - val_loss: 0.1298 - val_accuracy: 0.6667\n",
            "Epoch 80/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1017 - accuracy: 0.6122 - val_loss: 0.1285 - val_accuracy: 0.6667\n",
            "Epoch 81/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1005 - accuracy: 0.6054 - val_loss: 0.1274 - val_accuracy: 0.6667\n",
            "Epoch 82/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1000 - accuracy: 0.6122 - val_loss: 0.1262 - val_accuracy: 0.6667\n",
            "Epoch 83/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0981 - accuracy: 0.6122 - val_loss: 0.1256 - val_accuracy: 0.6667\n",
            "Epoch 84/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0975 - accuracy: 0.6054 - val_loss: 0.1234 - val_accuracy: 0.6667\n",
            "Epoch 85/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0956 - accuracy: 0.6054 - val_loss: 0.1222 - val_accuracy: 0.6667\n",
            "Epoch 86/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0947 - accuracy: 0.6122 - val_loss: 0.1210 - val_accuracy: 0.6667\n",
            "Epoch 87/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0944 - accuracy: 0.6122 - val_loss: 0.1201 - val_accuracy: 0.6667\n",
            "Epoch 88/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0927 - accuracy: 0.6122 - val_loss: 0.1188 - val_accuracy: 0.6667\n",
            "Epoch 89/500\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0920 - accuracy: 0.6054 - val_loss: 0.1179 - val_accuracy: 0.6667\n",
            "Epoch 90/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0911 - accuracy: 0.6054 - val_loss: 0.1169 - val_accuracy: 0.6667\n",
            "Epoch 91/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0903 - accuracy: 0.6122 - val_loss: 0.1163 - val_accuracy: 0.6667\n",
            "Epoch 92/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0891 - accuracy: 0.6122 - val_loss: 0.1160 - val_accuracy: 0.6667\n",
            "Epoch 93/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0890 - accuracy: 0.6054 - val_loss: 0.1151 - val_accuracy: 0.6667\n",
            "Epoch 94/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0878 - accuracy: 0.6122 - val_loss: 0.1134 - val_accuracy: 0.6667\n",
            "Epoch 95/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0873 - accuracy: 0.6122 - val_loss: 0.1126 - val_accuracy: 0.6667\n",
            "Epoch 96/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0866 - accuracy: 0.6122 - val_loss: 0.1131 - val_accuracy: 0.6667\n",
            "Epoch 97/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0859 - accuracy: 0.6122 - val_loss: 0.1113 - val_accuracy: 0.6667\n",
            "Epoch 98/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0847 - accuracy: 0.6122 - val_loss: 0.1105 - val_accuracy: 0.6667\n",
            "Epoch 99/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0841 - accuracy: 0.6122 - val_loss: 0.1098 - val_accuracy: 0.6667\n",
            "Epoch 100/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0836 - accuracy: 0.6122 - val_loss: 0.1092 - val_accuracy: 0.6508\n",
            "Epoch 101/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0828 - accuracy: 0.6190 - val_loss: 0.1093 - val_accuracy: 0.6508\n",
            "Epoch 102/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0820 - accuracy: 0.6122 - val_loss: 0.1103 - val_accuracy: 0.6667\n",
            "Epoch 103/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0822 - accuracy: 0.6122 - val_loss: 0.1080 - val_accuracy: 0.6508\n",
            "Epoch 104/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0807 - accuracy: 0.6190 - val_loss: 0.1070 - val_accuracy: 0.6508\n",
            "Epoch 105/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0802 - accuracy: 0.6122 - val_loss: 0.1065 - val_accuracy: 0.6667\n",
            "Epoch 106/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0793 - accuracy: 0.6122 - val_loss: 0.1056 - val_accuracy: 0.6667\n",
            "Epoch 107/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0787 - accuracy: 0.6122 - val_loss: 0.1051 - val_accuracy: 0.6508\n",
            "Epoch 108/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0782 - accuracy: 0.6122 - val_loss: 0.1043 - val_accuracy: 0.6508\n",
            "Epoch 109/500\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0776 - accuracy: 0.6122 - val_loss: 0.1035 - val_accuracy: 0.6508\n",
            "Epoch 110/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0774 - accuracy: 0.6122 - val_loss: 0.1038 - val_accuracy: 0.6508\n",
            "Epoch 111/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0762 - accuracy: 0.6122 - val_loss: 0.1036 - val_accuracy: 0.6508\n",
            "Epoch 112/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0754 - accuracy: 0.6122 - val_loss: 0.1025 - val_accuracy: 0.6508\n",
            "Epoch 113/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0749 - accuracy: 0.6122 - val_loss: 0.1011 - val_accuracy: 0.6508\n",
            "Epoch 114/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0742 - accuracy: 0.6122 - val_loss: 0.1013 - val_accuracy: 0.6667\n",
            "Epoch 115/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0736 - accuracy: 0.6122 - val_loss: 0.1009 - val_accuracy: 0.6508\n",
            "Epoch 116/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0729 - accuracy: 0.6190 - val_loss: 0.0997 - val_accuracy: 0.6667\n",
            "Epoch 117/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0725 - accuracy: 0.6190 - val_loss: 0.0995 - val_accuracy: 0.6667\n",
            "Epoch 118/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0716 - accuracy: 0.6190 - val_loss: 0.0993 - val_accuracy: 0.6508\n",
            "Epoch 119/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0707 - accuracy: 0.6190 - val_loss: 0.0990 - val_accuracy: 0.6508\n",
            "Epoch 120/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0702 - accuracy: 0.6190 - val_loss: 0.0982 - val_accuracy: 0.6508\n",
            "Epoch 121/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0698 - accuracy: 0.6190 - val_loss: 0.0976 - val_accuracy: 0.6667\n",
            "Epoch 122/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0694 - accuracy: 0.6190 - val_loss: 0.0974 - val_accuracy: 0.6667\n",
            "Epoch 123/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0689 - accuracy: 0.6190 - val_loss: 0.0972 - val_accuracy: 0.6667\n",
            "Epoch 124/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0691 - accuracy: 0.6190 - val_loss: 0.0964 - val_accuracy: 0.6667\n",
            "Epoch 125/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0686 - accuracy: 0.6190 - val_loss: 0.0966 - val_accuracy: 0.6667\n",
            "Epoch 126/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0678 - accuracy: 0.6190 - val_loss: 0.0954 - val_accuracy: 0.6667\n",
            "Epoch 127/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0671 - accuracy: 0.6190 - val_loss: 0.0953 - val_accuracy: 0.6667\n",
            "Epoch 128/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0667 - accuracy: 0.6190 - val_loss: 0.0950 - val_accuracy: 0.6667\n",
            "Epoch 129/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0664 - accuracy: 0.6190 - val_loss: 0.0940 - val_accuracy: 0.6667\n",
            "Epoch 130/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0662 - accuracy: 0.6190 - val_loss: 0.0937 - val_accuracy: 0.6508\n",
            "Epoch 131/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0657 - accuracy: 0.6190 - val_loss: 0.0934 - val_accuracy: 0.6508\n",
            "Epoch 132/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0652 - accuracy: 0.6190 - val_loss: 0.0934 - val_accuracy: 0.6667\n",
            "Epoch 133/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0646 - accuracy: 0.6190 - val_loss: 0.0931 - val_accuracy: 0.6667\n",
            "Epoch 134/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0644 - accuracy: 0.6190 - val_loss: 0.0930 - val_accuracy: 0.6667\n",
            "Epoch 135/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0641 - accuracy: 0.6190 - val_loss: 0.0921 - val_accuracy: 0.6508\n",
            "Epoch 136/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0634 - accuracy: 0.6190 - val_loss: 0.0918 - val_accuracy: 0.6508\n",
            "Epoch 137/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0635 - accuracy: 0.6122 - val_loss: 0.0912 - val_accuracy: 0.6508\n",
            "Epoch 138/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0629 - accuracy: 0.6190 - val_loss: 0.0908 - val_accuracy: 0.6667\n",
            "Epoch 139/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0630 - accuracy: 0.6190 - val_loss: 0.0905 - val_accuracy: 0.6667\n",
            "Epoch 140/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0627 - accuracy: 0.6190 - val_loss: 0.0907 - val_accuracy: 0.6667\n",
            "Epoch 141/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0620 - accuracy: 0.6190 - val_loss: 0.0904 - val_accuracy: 0.6667\n",
            "Epoch 142/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0615 - accuracy: 0.6190 - val_loss: 0.0895 - val_accuracy: 0.6508\n",
            "Epoch 143/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0612 - accuracy: 0.6190 - val_loss: 0.0891 - val_accuracy: 0.6508\n",
            "Epoch 144/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0608 - accuracy: 0.6190 - val_loss: 0.0890 - val_accuracy: 0.6508\n",
            "Epoch 145/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0606 - accuracy: 0.6190 - val_loss: 0.0890 - val_accuracy: 0.6508\n",
            "Epoch 146/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0610 - accuracy: 0.6122 - val_loss: 0.0883 - val_accuracy: 0.6667\n",
            "Epoch 147/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0606 - accuracy: 0.6122 - val_loss: 0.0877 - val_accuracy: 0.6667\n",
            "Epoch 148/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0599 - accuracy: 0.6122 - val_loss: 0.0878 - val_accuracy: 0.6508\n",
            "Epoch 149/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0593 - accuracy: 0.6190 - val_loss: 0.0876 - val_accuracy: 0.6508\n",
            "Epoch 150/500\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0591 - accuracy: 0.6190 - val_loss: 0.0876 - val_accuracy: 0.6667\n",
            "Epoch 151/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0588 - accuracy: 0.6190 - val_loss: 0.0871 - val_accuracy: 0.6667\n",
            "Epoch 152/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0583 - accuracy: 0.6190 - val_loss: 0.0869 - val_accuracy: 0.6508\n",
            "Epoch 153/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0581 - accuracy: 0.6190 - val_loss: 0.0867 - val_accuracy: 0.6508\n",
            "Epoch 154/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0580 - accuracy: 0.6190 - val_loss: 0.0866 - val_accuracy: 0.6508\n",
            "Epoch 155/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0574 - accuracy: 0.6190 - val_loss: 0.0860 - val_accuracy: 0.6508\n",
            "Epoch 156/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0575 - accuracy: 0.6190 - val_loss: 0.0859 - val_accuracy: 0.6667\n",
            "Epoch 157/500\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0571 - accuracy: 0.6190 - val_loss: 0.0861 - val_accuracy: 0.6667\n",
            "Epoch 158/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0572 - accuracy: 0.6190 - val_loss: 0.0857 - val_accuracy: 0.6508\n",
            "Epoch 159/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0566 - accuracy: 0.6190 - val_loss: 0.0849 - val_accuracy: 0.6667\n",
            "Epoch 160/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0562 - accuracy: 0.6190 - val_loss: 0.0851 - val_accuracy: 0.6667\n",
            "Epoch 161/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0559 - accuracy: 0.6190 - val_loss: 0.0851 - val_accuracy: 0.6667\n",
            "Epoch 162/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0558 - accuracy: 0.6190 - val_loss: 0.0845 - val_accuracy: 0.6667\n",
            "Epoch 163/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0555 - accuracy: 0.6190 - val_loss: 0.0846 - val_accuracy: 0.6667\n",
            "Epoch 164/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0552 - accuracy: 0.6190 - val_loss: 0.0843 - val_accuracy: 0.6667\n",
            "Epoch 165/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0549 - accuracy: 0.6190 - val_loss: 0.0839 - val_accuracy: 0.6667\n",
            "Epoch 166/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0547 - accuracy: 0.6190 - val_loss: 0.0842 - val_accuracy: 0.6667\n",
            "Epoch 167/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0548 - accuracy: 0.6190 - val_loss: 0.0841 - val_accuracy: 0.6667\n",
            "Epoch 168/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0544 - accuracy: 0.6190 - val_loss: 0.0832 - val_accuracy: 0.6667\n",
            "Epoch 169/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0544 - accuracy: 0.6190 - val_loss: 0.0831 - val_accuracy: 0.6508\n",
            "Epoch 170/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0540 - accuracy: 0.6190 - val_loss: 0.0833 - val_accuracy: 0.6667\n",
            "Epoch 171/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0538 - accuracy: 0.6190 - val_loss: 0.0827 - val_accuracy: 0.6667\n",
            "Epoch 172/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0536 - accuracy: 0.6190 - val_loss: 0.0823 - val_accuracy: 0.6667\n",
            "Epoch 173/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0530 - accuracy: 0.6190 - val_loss: 0.0821 - val_accuracy: 0.6667\n",
            "Epoch 174/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0532 - accuracy: 0.6190 - val_loss: 0.0819 - val_accuracy: 0.6667\n",
            "Epoch 175/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0531 - accuracy: 0.6190 - val_loss: 0.0826 - val_accuracy: 0.6508\n",
            "Epoch 176/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0526 - accuracy: 0.6190 - val_loss: 0.0815 - val_accuracy: 0.6667\n",
            "Epoch 177/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0528 - accuracy: 0.6190 - val_loss: 0.0817 - val_accuracy: 0.6667\n",
            "Epoch 178/500\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0520 - accuracy: 0.6190 - val_loss: 0.0824 - val_accuracy: 0.6667\n",
            "Epoch 179/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0521 - accuracy: 0.6190 - val_loss: 0.0814 - val_accuracy: 0.6667\n",
            "Epoch 180/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0516 - accuracy: 0.6190 - val_loss: 0.0809 - val_accuracy: 0.6667\n",
            "Epoch 181/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0516 - accuracy: 0.6190 - val_loss: 0.0808 - val_accuracy: 0.6667\n",
            "Epoch 182/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0517 - accuracy: 0.6190 - val_loss: 0.0812 - val_accuracy: 0.6667\n",
            "Epoch 183/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0516 - accuracy: 0.6190 - val_loss: 0.0810 - val_accuracy: 0.6667\n",
            "Epoch 184/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0518 - accuracy: 0.6190 - val_loss: 0.0798 - val_accuracy: 0.6508\n",
            "Epoch 185/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0512 - accuracy: 0.6190 - val_loss: 0.0797 - val_accuracy: 0.6667\n",
            "Epoch 186/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0509 - accuracy: 0.6190 - val_loss: 0.0804 - val_accuracy: 0.6667\n",
            "Epoch 187/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0510 - accuracy: 0.6190 - val_loss: 0.0811 - val_accuracy: 0.6667\n",
            "Epoch 188/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0502 - accuracy: 0.6190 - val_loss: 0.0794 - val_accuracy: 0.6667\n",
            "Epoch 189/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0506 - accuracy: 0.6190 - val_loss: 0.0797 - val_accuracy: 0.6667\n",
            "Epoch 190/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0504 - accuracy: 0.6190 - val_loss: 0.0800 - val_accuracy: 0.6667\n",
            "Epoch 191/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0500 - accuracy: 0.6190 - val_loss: 0.0801 - val_accuracy: 0.6667\n",
            "Epoch 192/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0497 - accuracy: 0.6190 - val_loss: 0.0795 - val_accuracy: 0.6667\n",
            "Epoch 193/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0496 - accuracy: 0.6190 - val_loss: 0.0794 - val_accuracy: 0.6667\n",
            "Epoch 194/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0492 - accuracy: 0.6190 - val_loss: 0.0792 - val_accuracy: 0.6667\n",
            "Epoch 195/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0489 - accuracy: 0.6190 - val_loss: 0.0787 - val_accuracy: 0.6667\n",
            "Epoch 196/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0491 - accuracy: 0.6190 - val_loss: 0.0786 - val_accuracy: 0.6667\n",
            "Epoch 197/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0487 - accuracy: 0.6190 - val_loss: 0.0793 - val_accuracy: 0.6667\n",
            "Epoch 198/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0487 - accuracy: 0.6190 - val_loss: 0.0790 - val_accuracy: 0.6667\n",
            "Epoch 199/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0484 - accuracy: 0.6190 - val_loss: 0.0785 - val_accuracy: 0.6667\n",
            "Epoch 200/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0484 - accuracy: 0.6190 - val_loss: 0.0782 - val_accuracy: 0.6667\n",
            "Epoch 201/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0480 - accuracy: 0.6190 - val_loss: 0.0788 - val_accuracy: 0.6667\n",
            "Epoch 202/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0483 - accuracy: 0.6190 - val_loss: 0.0782 - val_accuracy: 0.6667\n",
            "Epoch 203/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0478 - accuracy: 0.6190 - val_loss: 0.0778 - val_accuracy: 0.6667\n",
            "Epoch 204/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0477 - accuracy: 0.6190 - val_loss: 0.0780 - val_accuracy: 0.6667\n",
            "Epoch 205/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0476 - accuracy: 0.6190 - val_loss: 0.0783 - val_accuracy: 0.6667\n",
            "Epoch 206/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0478 - accuracy: 0.6190 - val_loss: 0.0774 - val_accuracy: 0.6667\n",
            "Epoch 207/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0477 - accuracy: 0.6190 - val_loss: 0.0776 - val_accuracy: 0.6667\n",
            "Epoch 208/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0471 - accuracy: 0.6190 - val_loss: 0.0773 - val_accuracy: 0.6667\n",
            "Epoch 209/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0469 - accuracy: 0.6190 - val_loss: 0.0776 - val_accuracy: 0.6667\n",
            "Epoch 210/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0469 - accuracy: 0.6190 - val_loss: 0.0776 - val_accuracy: 0.6667\n",
            "Epoch 211/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0467 - accuracy: 0.6190 - val_loss: 0.0770 - val_accuracy: 0.6667\n",
            "Epoch 212/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0465 - accuracy: 0.6190 - val_loss: 0.0768 - val_accuracy: 0.6667\n",
            "Epoch 213/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0464 - accuracy: 0.6190 - val_loss: 0.0765 - val_accuracy: 0.6667\n",
            "Epoch 214/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0463 - accuracy: 0.6190 - val_loss: 0.0771 - val_accuracy: 0.6667\n",
            "Epoch 215/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0461 - accuracy: 0.6190 - val_loss: 0.0768 - val_accuracy: 0.6667\n",
            "Epoch 216/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0461 - accuracy: 0.6190 - val_loss: 0.0763 - val_accuracy: 0.6667\n",
            "Epoch 217/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0459 - accuracy: 0.6190 - val_loss: 0.0768 - val_accuracy: 0.6667\n",
            "Epoch 218/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0458 - accuracy: 0.6190 - val_loss: 0.0762 - val_accuracy: 0.6667\n",
            "Epoch 219/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0459 - accuracy: 0.6190 - val_loss: 0.0762 - val_accuracy: 0.6667\n",
            "Epoch 220/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0458 - accuracy: 0.6190 - val_loss: 0.0765 - val_accuracy: 0.6667\n",
            "Epoch 221/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0453 - accuracy: 0.6190 - val_loss: 0.0752 - val_accuracy: 0.6667\n",
            "Epoch 222/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0455 - accuracy: 0.6190 - val_loss: 0.0753 - val_accuracy: 0.6667\n",
            "Epoch 223/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0452 - accuracy: 0.6190 - val_loss: 0.0762 - val_accuracy: 0.6667\n",
            "Epoch 224/500\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0451 - accuracy: 0.6190 - val_loss: 0.0755 - val_accuracy: 0.6667\n",
            "Epoch 225/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0452 - accuracy: 0.6190 - val_loss: 0.0755 - val_accuracy: 0.6667\n",
            "Epoch 226/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0449 - accuracy: 0.6190 - val_loss: 0.0760 - val_accuracy: 0.6667\n",
            "Epoch 227/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0447 - accuracy: 0.6190 - val_loss: 0.0750 - val_accuracy: 0.6667\n",
            "Epoch 228/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0447 - accuracy: 0.6190 - val_loss: 0.0750 - val_accuracy: 0.6667\n",
            "Epoch 229/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0445 - accuracy: 0.6190 - val_loss: 0.0752 - val_accuracy: 0.6667\n",
            "Epoch 230/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0442 - accuracy: 0.6190 - val_loss: 0.0751 - val_accuracy: 0.6667\n",
            "Epoch 231/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0442 - accuracy: 0.6190 - val_loss: 0.0750 - val_accuracy: 0.6667\n",
            "Epoch 232/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0440 - accuracy: 0.6190 - val_loss: 0.0751 - val_accuracy: 0.6667\n",
            "Epoch 233/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0439 - accuracy: 0.6190 - val_loss: 0.0742 - val_accuracy: 0.6667\n",
            "Epoch 234/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0440 - accuracy: 0.6190 - val_loss: 0.0744 - val_accuracy: 0.6667\n",
            "Epoch 235/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0437 - accuracy: 0.6190 - val_loss: 0.0747 - val_accuracy: 0.6667\n",
            "Epoch 236/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0437 - accuracy: 0.6190 - val_loss: 0.0749 - val_accuracy: 0.6667\n",
            "Epoch 237/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0434 - accuracy: 0.6190 - val_loss: 0.0742 - val_accuracy: 0.6667\n",
            "Epoch 238/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0439 - accuracy: 0.6190 - val_loss: 0.0748 - val_accuracy: 0.6667\n",
            "Epoch 239/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0433 - accuracy: 0.6190 - val_loss: 0.0745 - val_accuracy: 0.6667\n",
            "Epoch 240/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0434 - accuracy: 0.6190 - val_loss: 0.0737 - val_accuracy: 0.6667\n",
            "Epoch 241/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0433 - accuracy: 0.6190 - val_loss: 0.0739 - val_accuracy: 0.6667\n",
            "Epoch 242/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0432 - accuracy: 0.6190 - val_loss: 0.0739 - val_accuracy: 0.6667\n",
            "Epoch 243/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0428 - accuracy: 0.6190 - val_loss: 0.0738 - val_accuracy: 0.6667\n",
            "Epoch 244/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0426 - accuracy: 0.6190 - val_loss: 0.0739 - val_accuracy: 0.6667\n",
            "Epoch 245/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0426 - accuracy: 0.6190 - val_loss: 0.0738 - val_accuracy: 0.6667\n",
            "Epoch 246/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0428 - accuracy: 0.6190 - val_loss: 0.0740 - val_accuracy: 0.6667\n",
            "Epoch 247/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0423 - accuracy: 0.6190 - val_loss: 0.0734 - val_accuracy: 0.6667\n",
            "Epoch 248/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0424 - accuracy: 0.6190 - val_loss: 0.0733 - val_accuracy: 0.6667\n",
            "Epoch 249/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0424 - accuracy: 0.6190 - val_loss: 0.0739 - val_accuracy: 0.6667\n",
            "Epoch 250/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0423 - accuracy: 0.6190 - val_loss: 0.0729 - val_accuracy: 0.6667\n",
            "Epoch 251/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0426 - accuracy: 0.6190 - val_loss: 0.0726 - val_accuracy: 0.6667\n",
            "Epoch 252/500\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0420 - accuracy: 0.6190 - val_loss: 0.0744 - val_accuracy: 0.6667\n",
            "Epoch 253/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0425 - accuracy: 0.6190 - val_loss: 0.0732 - val_accuracy: 0.6667\n",
            "Epoch 254/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0421 - accuracy: 0.6190 - val_loss: 0.0725 - val_accuracy: 0.6667\n",
            "Epoch 255/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0421 - accuracy: 0.6190 - val_loss: 0.0738 - val_accuracy: 0.6667\n",
            "Epoch 256/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0423 - accuracy: 0.6190 - val_loss: 0.0733 - val_accuracy: 0.6667\n",
            "Epoch 257/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0416 - accuracy: 0.6190 - val_loss: 0.0722 - val_accuracy: 0.6667\n",
            "Epoch 258/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0420 - accuracy: 0.6190 - val_loss: 0.0725 - val_accuracy: 0.6667\n",
            "Epoch 259/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0418 - accuracy: 0.6190 - val_loss: 0.0741 - val_accuracy: 0.6667\n",
            "Epoch 260/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0422 - accuracy: 0.6190 - val_loss: 0.0721 - val_accuracy: 0.6667\n",
            "Epoch 261/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0413 - accuracy: 0.6190 - val_loss: 0.0721 - val_accuracy: 0.6667\n",
            "Epoch 262/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0412 - accuracy: 0.6190 - val_loss: 0.0723 - val_accuracy: 0.6667\n",
            "Epoch 263/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0411 - accuracy: 0.6190 - val_loss: 0.0717 - val_accuracy: 0.6667\n",
            "Epoch 264/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0409 - accuracy: 0.6190 - val_loss: 0.0721 - val_accuracy: 0.6667\n",
            "Epoch 265/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0408 - accuracy: 0.6190 - val_loss: 0.0726 - val_accuracy: 0.6667\n",
            "Epoch 266/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0408 - accuracy: 0.6190 - val_loss: 0.0722 - val_accuracy: 0.6667\n",
            "Epoch 267/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0411 - accuracy: 0.6190 - val_loss: 0.0718 - val_accuracy: 0.6667\n",
            "Epoch 268/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0411 - accuracy: 0.6190 - val_loss: 0.0715 - val_accuracy: 0.6667\n",
            "Epoch 269/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0404 - accuracy: 0.6190 - val_loss: 0.0722 - val_accuracy: 0.6667\n",
            "Epoch 270/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0404 - accuracy: 0.6190 - val_loss: 0.0719 - val_accuracy: 0.6667\n",
            "Epoch 271/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0402 - accuracy: 0.6190 - val_loss: 0.0715 - val_accuracy: 0.6667\n",
            "Epoch 272/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0407 - accuracy: 0.6190 - val_loss: 0.0716 - val_accuracy: 0.6667\n",
            "Epoch 273/500\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0402 - accuracy: 0.6190 - val_loss: 0.0719 - val_accuracy: 0.6667\n",
            "Epoch 274/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0400 - accuracy: 0.6190 - val_loss: 0.0712 - val_accuracy: 0.6667\n",
            "Epoch 275/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0399 - accuracy: 0.6190 - val_loss: 0.0712 - val_accuracy: 0.6667\n",
            "Epoch 276/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0398 - accuracy: 0.6190 - val_loss: 0.0715 - val_accuracy: 0.6667\n",
            "Epoch 277/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0401 - accuracy: 0.6190 - val_loss: 0.0710 - val_accuracy: 0.6667\n",
            "Epoch 278/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0397 - accuracy: 0.6190 - val_loss: 0.0713 - val_accuracy: 0.6667\n",
            "Epoch 279/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0398 - accuracy: 0.6190 - val_loss: 0.0703 - val_accuracy: 0.6667\n",
            "Epoch 280/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0398 - accuracy: 0.6190 - val_loss: 0.0709 - val_accuracy: 0.6667\n",
            "Epoch 281/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0396 - accuracy: 0.6190 - val_loss: 0.0707 - val_accuracy: 0.6667\n",
            "Epoch 282/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0394 - accuracy: 0.6190 - val_loss: 0.0707 - val_accuracy: 0.6667\n",
            "Epoch 283/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0397 - accuracy: 0.6190 - val_loss: 0.0704 - val_accuracy: 0.6667\n",
            "Epoch 284/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0397 - accuracy: 0.6190 - val_loss: 0.0716 - val_accuracy: 0.6667\n",
            "Epoch 285/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0392 - accuracy: 0.6190 - val_loss: 0.0703 - val_accuracy: 0.6667\n",
            "Epoch 286/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0393 - accuracy: 0.6190 - val_loss: 0.0705 - val_accuracy: 0.6667\n",
            "Epoch 287/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0396 - accuracy: 0.6190 - val_loss: 0.0710 - val_accuracy: 0.6667\n",
            "Epoch 288/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0388 - accuracy: 0.6190 - val_loss: 0.0701 - val_accuracy: 0.6667\n",
            "Epoch 289/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0389 - accuracy: 0.6190 - val_loss: 0.0705 - val_accuracy: 0.6667\n",
            "Epoch 290/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0391 - accuracy: 0.6190 - val_loss: 0.0708 - val_accuracy: 0.6667\n",
            "Epoch 291/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0391 - accuracy: 0.6190 - val_loss: 0.0699 - val_accuracy: 0.6667\n",
            "Epoch 292/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0388 - accuracy: 0.6190 - val_loss: 0.0704 - val_accuracy: 0.6667\n",
            "Epoch 293/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0388 - accuracy: 0.6190 - val_loss: 0.0700 - val_accuracy: 0.6667\n",
            "Epoch 294/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0386 - accuracy: 0.6190 - val_loss: 0.0697 - val_accuracy: 0.6667\n",
            "Epoch 295/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0384 - accuracy: 0.6190 - val_loss: 0.0699 - val_accuracy: 0.6667\n",
            "Epoch 296/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0383 - accuracy: 0.6190 - val_loss: 0.0700 - val_accuracy: 0.6667\n",
            "Epoch 297/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0383 - accuracy: 0.6190 - val_loss: 0.0700 - val_accuracy: 0.6667\n",
            "Epoch 298/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0381 - accuracy: 0.6190 - val_loss: 0.0704 - val_accuracy: 0.6667\n",
            "Epoch 299/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0384 - accuracy: 0.6190 - val_loss: 0.0705 - val_accuracy: 0.6667\n",
            "Epoch 300/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0381 - accuracy: 0.6190 - val_loss: 0.0695 - val_accuracy: 0.6667\n",
            "Epoch 301/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0380 - accuracy: 0.6190 - val_loss: 0.0699 - val_accuracy: 0.6667\n",
            "Epoch 302/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0380 - accuracy: 0.6190 - val_loss: 0.0695 - val_accuracy: 0.6667\n",
            "Epoch 303/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0379 - accuracy: 0.6190 - val_loss: 0.0696 - val_accuracy: 0.6667\n",
            "Epoch 304/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0379 - accuracy: 0.6190 - val_loss: 0.0697 - val_accuracy: 0.6667\n",
            "Epoch 305/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0384 - accuracy: 0.6190 - val_loss: 0.0695 - val_accuracy: 0.6667\n",
            "Epoch 306/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0379 - accuracy: 0.6190 - val_loss: 0.0699 - val_accuracy: 0.6667\n",
            "Epoch 307/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0382 - accuracy: 0.6190 - val_loss: 0.0693 - val_accuracy: 0.6667\n",
            "Epoch 308/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0380 - accuracy: 0.6190 - val_loss: 0.0695 - val_accuracy: 0.6667\n",
            "Epoch 309/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0375 - accuracy: 0.6190 - val_loss: 0.0687 - val_accuracy: 0.6667\n",
            "Epoch 310/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0372 - accuracy: 0.6190 - val_loss: 0.0688 - val_accuracy: 0.6667\n",
            "Epoch 311/500\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0367 - accuracy: 0.6190 - val_loss: 0.0686 - val_accuracy: 0.6667\n",
            "Epoch 312/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0369 - accuracy: 0.6190 - val_loss: 0.0686 - val_accuracy: 0.6667\n",
            "Epoch 313/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0365 - accuracy: 0.6190 - val_loss: 0.0686 - val_accuracy: 0.6667\n",
            "Epoch 314/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0367 - accuracy: 0.6190 - val_loss: 0.0692 - val_accuracy: 0.6667\n",
            "Epoch 315/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0371 - accuracy: 0.6190 - val_loss: 0.0683 - val_accuracy: 0.6667\n",
            "Epoch 316/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0365 - accuracy: 0.6190 - val_loss: 0.0684 - val_accuracy: 0.6667\n",
            "Epoch 317/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0362 - accuracy: 0.6190 - val_loss: 0.0685 - val_accuracy: 0.6667\n",
            "Epoch 318/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0361 - accuracy: 0.6190 - val_loss: 0.0685 - val_accuracy: 0.6667\n",
            "Epoch 319/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0360 - accuracy: 0.6190 - val_loss: 0.0683 - val_accuracy: 0.6667\n",
            "Epoch 320/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0360 - accuracy: 0.6190 - val_loss: 0.0682 - val_accuracy: 0.6667\n",
            "Epoch 321/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0369 - accuracy: 0.6190 - val_loss: 0.0688 - val_accuracy: 0.6667\n",
            "Epoch 322/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0365 - accuracy: 0.6190 - val_loss: 0.0684 - val_accuracy: 0.6667\n",
            "Epoch 323/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0364 - accuracy: 0.6190 - val_loss: 0.0690 - val_accuracy: 0.6667\n",
            "Epoch 324/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0363 - accuracy: 0.6190 - val_loss: 0.0678 - val_accuracy: 0.6667\n",
            "Epoch 325/500\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0368 - accuracy: 0.6190 - val_loss: 0.0680 - val_accuracy: 0.6667\n",
            "Epoch 326/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0360 - accuracy: 0.6190 - val_loss: 0.0683 - val_accuracy: 0.6667\n",
            "Epoch 327/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0363 - accuracy: 0.6190 - val_loss: 0.0678 - val_accuracy: 0.6667\n",
            "Epoch 328/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0354 - accuracy: 0.6190 - val_loss: 0.0681 - val_accuracy: 0.6667\n",
            "Epoch 329/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0354 - accuracy: 0.6190 - val_loss: 0.0680 - val_accuracy: 0.6667\n",
            "Epoch 330/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0354 - accuracy: 0.6190 - val_loss: 0.0678 - val_accuracy: 0.6667\n",
            "Epoch 331/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0354 - accuracy: 0.6190 - val_loss: 0.0676 - val_accuracy: 0.6667\n",
            "Epoch 332/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0355 - accuracy: 0.6190 - val_loss: 0.0679 - val_accuracy: 0.6667\n",
            "Epoch 333/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0355 - accuracy: 0.6190 - val_loss: 0.0677 - val_accuracy: 0.6667\n",
            "Epoch 334/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0352 - accuracy: 0.6190 - val_loss: 0.0676 - val_accuracy: 0.6667\n",
            "Epoch 335/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0351 - accuracy: 0.6190 - val_loss: 0.0676 - val_accuracy: 0.6667\n",
            "Epoch 336/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0352 - accuracy: 0.6190 - val_loss: 0.0672 - val_accuracy: 0.6667\n",
            "Epoch 337/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0351 - accuracy: 0.6190 - val_loss: 0.0672 - val_accuracy: 0.6667\n",
            "Epoch 338/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0349 - accuracy: 0.6190 - val_loss: 0.0678 - val_accuracy: 0.6667\n",
            "Epoch 339/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0352 - accuracy: 0.6190 - val_loss: 0.0670 - val_accuracy: 0.6667\n",
            "Epoch 340/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0351 - accuracy: 0.6190 - val_loss: 0.0669 - val_accuracy: 0.6667\n",
            "Epoch 341/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0351 - accuracy: 0.6190 - val_loss: 0.0672 - val_accuracy: 0.6667\n",
            "Epoch 342/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0356 - accuracy: 0.6190 - val_loss: 0.0671 - val_accuracy: 0.6667\n",
            "Epoch 343/500\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0351 - accuracy: 0.6190 - val_loss: 0.0671 - val_accuracy: 0.6667\n",
            "Epoch 344/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0351 - accuracy: 0.6190 - val_loss: 0.0674 - val_accuracy: 0.6667\n",
            "Epoch 345/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0357 - accuracy: 0.6190 - val_loss: 0.0668 - val_accuracy: 0.6667\n",
            "Epoch 346/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0350 - accuracy: 0.6190 - val_loss: 0.0667 - val_accuracy: 0.6667\n",
            "Epoch 347/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0347 - accuracy: 0.6190 - val_loss: 0.0665 - val_accuracy: 0.6667\n",
            "Epoch 348/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0349 - accuracy: 0.6190 - val_loss: 0.0670 - val_accuracy: 0.6667\n",
            "Epoch 349/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0349 - accuracy: 0.6190 - val_loss: 0.0669 - val_accuracy: 0.6667\n",
            "Epoch 350/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0346 - accuracy: 0.6190 - val_loss: 0.0670 - val_accuracy: 0.6667\n",
            "Epoch 351/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0347 - accuracy: 0.6190 - val_loss: 0.0664 - val_accuracy: 0.6667\n",
            "Epoch 352/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0346 - accuracy: 0.6190 - val_loss: 0.0666 - val_accuracy: 0.6667\n",
            "Epoch 353/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0344 - accuracy: 0.6190 - val_loss: 0.0666 - val_accuracy: 0.6667\n",
            "Epoch 354/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0343 - accuracy: 0.6190 - val_loss: 0.0671 - val_accuracy: 0.6667\n",
            "Epoch 355/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.6190 - val_loss: 0.0672 - val_accuracy: 0.6667\n",
            "Epoch 356/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0348 - accuracy: 0.6190 - val_loss: 0.0674 - val_accuracy: 0.6667\n",
            "Epoch 357/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0348 - accuracy: 0.6190 - val_loss: 0.0665 - val_accuracy: 0.6667\n",
            "Epoch 358/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0347 - accuracy: 0.6190 - val_loss: 0.0666 - val_accuracy: 0.6667\n",
            "Epoch 359/500\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0340 - accuracy: 0.6190 - val_loss: 0.0665 - val_accuracy: 0.6667\n",
            "Epoch 360/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0339 - accuracy: 0.6190 - val_loss: 0.0664 - val_accuracy: 0.6667\n",
            "Epoch 361/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0339 - accuracy: 0.6190 - val_loss: 0.0665 - val_accuracy: 0.6667\n",
            "Epoch 362/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0338 - accuracy: 0.6190 - val_loss: 0.0667 - val_accuracy: 0.6667\n",
            "Epoch 363/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0340 - accuracy: 0.6190 - val_loss: 0.0666 - val_accuracy: 0.6667\n",
            "Epoch 364/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0339 - accuracy: 0.6190 - val_loss: 0.0663 - val_accuracy: 0.6667\n",
            "Epoch 365/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0342 - accuracy: 0.6190 - val_loss: 0.0660 - val_accuracy: 0.6667\n",
            "Epoch 366/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0337 - accuracy: 0.6190 - val_loss: 0.0661 - val_accuracy: 0.6667\n",
            "Epoch 367/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0336 - accuracy: 0.6190 - val_loss: 0.0661 - val_accuracy: 0.6667\n",
            "Epoch 368/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0334 - accuracy: 0.6190 - val_loss: 0.0657 - val_accuracy: 0.6667\n",
            "Epoch 369/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0336 - accuracy: 0.6190 - val_loss: 0.0656 - val_accuracy: 0.6667\n",
            "Epoch 370/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0338 - accuracy: 0.6190 - val_loss: 0.0655 - val_accuracy: 0.6667\n",
            "Epoch 371/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0334 - accuracy: 0.6190 - val_loss: 0.0655 - val_accuracy: 0.6667\n",
            "Epoch 372/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0340 - accuracy: 0.6190 - val_loss: 0.0656 - val_accuracy: 0.6667\n",
            "Epoch 373/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0338 - accuracy: 0.6190 - val_loss: 0.0656 - val_accuracy: 0.6825\n",
            "Epoch 374/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0333 - accuracy: 0.6190 - val_loss: 0.0658 - val_accuracy: 0.6667\n",
            "Epoch 375/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0333 - accuracy: 0.6190 - val_loss: 0.0660 - val_accuracy: 0.6667\n",
            "Epoch 376/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0334 - accuracy: 0.6190 - val_loss: 0.0655 - val_accuracy: 0.6667\n",
            "Epoch 377/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0333 - accuracy: 0.6190 - val_loss: 0.0653 - val_accuracy: 0.6667\n",
            "Epoch 378/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0336 - accuracy: 0.6190 - val_loss: 0.0651 - val_accuracy: 0.6667\n",
            "Epoch 379/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0331 - accuracy: 0.6190 - val_loss: 0.0651 - val_accuracy: 0.6667\n",
            "Epoch 380/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0330 - accuracy: 0.6190 - val_loss: 0.0652 - val_accuracy: 0.6667\n",
            "Epoch 381/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0331 - accuracy: 0.6190 - val_loss: 0.0656 - val_accuracy: 0.6667\n",
            "Epoch 382/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0336 - accuracy: 0.6190 - val_loss: 0.0653 - val_accuracy: 0.6667\n",
            "Epoch 383/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0331 - accuracy: 0.6190 - val_loss: 0.0652 - val_accuracy: 0.6667\n",
            "Epoch 384/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0328 - accuracy: 0.6190 - val_loss: 0.0654 - val_accuracy: 0.6667\n",
            "Epoch 385/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0329 - accuracy: 0.6190 - val_loss: 0.0655 - val_accuracy: 0.6667\n",
            "Epoch 386/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0327 - accuracy: 0.6190 - val_loss: 0.0653 - val_accuracy: 0.6667\n",
            "Epoch 387/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0329 - accuracy: 0.6190 - val_loss: 0.0652 - val_accuracy: 0.6667\n",
            "Epoch 388/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0327 - accuracy: 0.6190 - val_loss: 0.0650 - val_accuracy: 0.6667\n",
            "Epoch 389/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0327 - accuracy: 0.6190 - val_loss: 0.0648 - val_accuracy: 0.6667\n",
            "Epoch 390/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0330 - accuracy: 0.6190 - val_loss: 0.0649 - val_accuracy: 0.6667\n",
            "Epoch 391/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0326 - accuracy: 0.6190 - val_loss: 0.0647 - val_accuracy: 0.6667\n",
            "Epoch 392/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0326 - accuracy: 0.6122 - val_loss: 0.0648 - val_accuracy: 0.6667\n",
            "Epoch 393/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0329 - accuracy: 0.6122 - val_loss: 0.0650 - val_accuracy: 0.6667\n",
            "Epoch 394/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0335 - accuracy: 0.6190 - val_loss: 0.0662 - val_accuracy: 0.6667\n",
            "Epoch 395/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0338 - accuracy: 0.6190 - val_loss: 0.0658 - val_accuracy: 0.6667\n",
            "Epoch 396/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0334 - accuracy: 0.6190 - val_loss: 0.0653 - val_accuracy: 0.6667\n",
            "Epoch 397/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0333 - accuracy: 0.6190 - val_loss: 0.0649 - val_accuracy: 0.6667\n",
            "Epoch 398/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0345 - accuracy: 0.6122 - val_loss: 0.0652 - val_accuracy: 0.6825\n",
            "Epoch 399/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0343 - accuracy: 0.6190 - val_loss: 0.0650 - val_accuracy: 0.6667\n",
            "Epoch 400/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0331 - accuracy: 0.6190 - val_loss: 0.0659 - val_accuracy: 0.6667\n",
            "Epoch 401/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0336 - accuracy: 0.6122 - val_loss: 0.0661 - val_accuracy: 0.6667\n",
            "Epoch 402/500\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0329 - accuracy: 0.6190 - val_loss: 0.0649 - val_accuracy: 0.6667\n",
            "Epoch 403/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0326 - accuracy: 0.6190 - val_loss: 0.0650 - val_accuracy: 0.6667\n",
            "Epoch 404/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0327 - accuracy: 0.6190 - val_loss: 0.0650 - val_accuracy: 0.6667\n",
            "Epoch 405/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0327 - accuracy: 0.6190 - val_loss: 0.0648 - val_accuracy: 0.6667\n",
            "Epoch 406/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0326 - accuracy: 0.6190 - val_loss: 0.0647 - val_accuracy: 0.6667\n",
            "Epoch 407/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0323 - accuracy: 0.6190 - val_loss: 0.0644 - val_accuracy: 0.6667\n",
            "Epoch 408/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0322 - accuracy: 0.6190 - val_loss: 0.0649 - val_accuracy: 0.6667\n",
            "Epoch 409/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0319 - accuracy: 0.6190 - val_loss: 0.0649 - val_accuracy: 0.6667\n",
            "Epoch 410/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0322 - accuracy: 0.6190 - val_loss: 0.0648 - val_accuracy: 0.6667\n",
            "Epoch 411/500\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0326 - accuracy: 0.6190 - val_loss: 0.0644 - val_accuracy: 0.6667\n",
            "Epoch 412/500\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0322 - accuracy: 0.6190 - val_loss: 0.0643 - val_accuracy: 0.6667\n",
            "Epoch 413/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0322 - accuracy: 0.6190 - val_loss: 0.0644 - val_accuracy: 0.6667\n",
            "Epoch 414/500\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0320 - accuracy: 0.6190 - val_loss: 0.0643 - val_accuracy: 0.6667\n",
            "Epoch 415/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0318 - accuracy: 0.6190 - val_loss: 0.0643 - val_accuracy: 0.6667\n",
            "Epoch 416/500\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0321 - accuracy: 0.6190 - val_loss: 0.0639 - val_accuracy: 0.6667\n",
            "Epoch 417/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0318 - accuracy: 0.6122 - val_loss: 0.0640 - val_accuracy: 0.6667\n",
            "Epoch 418/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0317 - accuracy: 0.6190 - val_loss: 0.0643 - val_accuracy: 0.6667\n",
            "Epoch 419/500\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0319 - accuracy: 0.6190 - val_loss: 0.0643 - val_accuracy: 0.6667\n",
            "Epoch 420/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0323 - accuracy: 0.6122 - val_loss: 0.0640 - val_accuracy: 0.6667\n",
            "Epoch 421/500\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0319 - accuracy: 0.6190 - val_loss: 0.0645 - val_accuracy: 0.6667\n",
            "Epoch 422/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0320 - accuracy: 0.6190 - val_loss: 0.0643 - val_accuracy: 0.6667\n",
            "Epoch 423/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0317 - accuracy: 0.6190 - val_loss: 0.0640 - val_accuracy: 0.6667\n",
            "Epoch 424/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0317 - accuracy: 0.6190 - val_loss: 0.0641 - val_accuracy: 0.6667\n",
            "Epoch 425/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0314 - accuracy: 0.6190 - val_loss: 0.0637 - val_accuracy: 0.6667\n",
            "Epoch 426/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0312 - accuracy: 0.6190 - val_loss: 0.0637 - val_accuracy: 0.6667\n",
            "Epoch 427/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0313 - accuracy: 0.6190 - val_loss: 0.0639 - val_accuracy: 0.6667\n",
            "Epoch 428/500\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0313 - accuracy: 0.6190 - val_loss: 0.0638 - val_accuracy: 0.6667\n",
            "Epoch 429/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0314 - accuracy: 0.6190 - val_loss: 0.0637 - val_accuracy: 0.6667\n",
            "Epoch 430/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0310 - accuracy: 0.6190 - val_loss: 0.0638 - val_accuracy: 0.6667\n",
            "Epoch 431/500\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0316 - accuracy: 0.6190 - val_loss: 0.0642 - val_accuracy: 0.6667\n",
            "Epoch 432/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0317 - accuracy: 0.6190 - val_loss: 0.0636 - val_accuracy: 0.6667\n",
            "Epoch 433/500\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0319 - accuracy: 0.6190 - val_loss: 0.0643 - val_accuracy: 0.6667\n",
            "Epoch 434/500\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0319 - accuracy: 0.6190 - val_loss: 0.0635 - val_accuracy: 0.6667\n",
            "Epoch 435/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0312 - accuracy: 0.6190 - val_loss: 0.0636 - val_accuracy: 0.6667\n",
            "Epoch 436/500\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0310 - accuracy: 0.6190 - val_loss: 0.0635 - val_accuracy: 0.6667\n",
            "Epoch 437/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0310 - accuracy: 0.6190 - val_loss: 0.0635 - val_accuracy: 0.6667\n",
            "Epoch 438/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0313 - accuracy: 0.6190 - val_loss: 0.0638 - val_accuracy: 0.6667\n",
            "Epoch 439/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0317 - accuracy: 0.6190 - val_loss: 0.0633 - val_accuracy: 0.6667\n",
            "Epoch 440/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0321 - accuracy: 0.6190 - val_loss: 0.0635 - val_accuracy: 0.6667\n",
            "Epoch 441/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0313 - accuracy: 0.6190 - val_loss: 0.0633 - val_accuracy: 0.6667\n",
            "Epoch 442/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0314 - accuracy: 0.6190 - val_loss: 0.0633 - val_accuracy: 0.6825\n",
            "Epoch 443/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0311 - accuracy: 0.6190 - val_loss: 0.0631 - val_accuracy: 0.6825\n",
            "Epoch 444/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0313 - accuracy: 0.6190 - val_loss: 0.0630 - val_accuracy: 0.6667\n",
            "Epoch 445/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0312 - accuracy: 0.6190 - val_loss: 0.0635 - val_accuracy: 0.6825\n",
            "Epoch 446/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0313 - accuracy: 0.6190 - val_loss: 0.0630 - val_accuracy: 0.6825\n",
            "Epoch 447/500\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0308 - accuracy: 0.6190 - val_loss: 0.0628 - val_accuracy: 0.6825\n",
            "Epoch 448/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0309 - accuracy: 0.6190 - val_loss: 0.0632 - val_accuracy: 0.6667\n",
            "Epoch 449/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0310 - accuracy: 0.6190 - val_loss: 0.0632 - val_accuracy: 0.6667\n",
            "Epoch 450/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0312 - accuracy: 0.6190 - val_loss: 0.0632 - val_accuracy: 0.6667\n",
            "Epoch 451/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0309 - accuracy: 0.6190 - val_loss: 0.0640 - val_accuracy: 0.6667\n",
            "Epoch 452/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0313 - accuracy: 0.6190 - val_loss: 0.0636 - val_accuracy: 0.6667\n",
            "Epoch 453/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0318 - accuracy: 0.6190 - val_loss: 0.0637 - val_accuracy: 0.6667\n",
            "Epoch 454/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0316 - accuracy: 0.6190 - val_loss: 0.0633 - val_accuracy: 0.6667\n",
            "Epoch 455/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0308 - accuracy: 0.6190 - val_loss: 0.0630 - val_accuracy: 0.6667\n",
            "Epoch 456/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0310 - accuracy: 0.6190 - val_loss: 0.0635 - val_accuracy: 0.6667\n",
            "Epoch 457/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0313 - accuracy: 0.6190 - val_loss: 0.0637 - val_accuracy: 0.6667\n",
            "Epoch 458/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0311 - accuracy: 0.6190 - val_loss: 0.0632 - val_accuracy: 0.6667\n",
            "Epoch 459/500\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0306 - accuracy: 0.6190 - val_loss: 0.0635 - val_accuracy: 0.6667\n",
            "Epoch 460/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0313 - accuracy: 0.6190 - val_loss: 0.0633 - val_accuracy: 0.6825\n",
            "Epoch 461/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0311 - accuracy: 0.6190 - val_loss: 0.0629 - val_accuracy: 0.6667\n",
            "Epoch 462/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0305 - accuracy: 0.6190 - val_loss: 0.0628 - val_accuracy: 0.6667\n",
            "Epoch 463/500\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0306 - accuracy: 0.6190 - val_loss: 0.0630 - val_accuracy: 0.6667\n",
            "Epoch 464/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0305 - accuracy: 0.6190 - val_loss: 0.0628 - val_accuracy: 0.6667\n",
            "Epoch 465/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0303 - accuracy: 0.6190 - val_loss: 0.0626 - val_accuracy: 0.6667\n",
            "Epoch 466/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0303 - accuracy: 0.6190 - val_loss: 0.0626 - val_accuracy: 0.6667\n",
            "Epoch 467/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0301 - accuracy: 0.6190 - val_loss: 0.0625 - val_accuracy: 0.6825\n",
            "Epoch 468/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0302 - accuracy: 0.6190 - val_loss: 0.0625 - val_accuracy: 0.6825\n",
            "Epoch 469/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0302 - accuracy: 0.6190 - val_loss: 0.0623 - val_accuracy: 0.6825\n",
            "Epoch 470/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0300 - accuracy: 0.6190 - val_loss: 0.0623 - val_accuracy: 0.6825\n",
            "Epoch 471/500\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0302 - accuracy: 0.6190 - val_loss: 0.0621 - val_accuracy: 0.6825\n",
            "Epoch 472/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0303 - accuracy: 0.6190 - val_loss: 0.0623 - val_accuracy: 0.6825\n",
            "Epoch 473/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0306 - accuracy: 0.6190 - val_loss: 0.0623 - val_accuracy: 0.6825\n",
            "Epoch 474/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0302 - accuracy: 0.6190 - val_loss: 0.0625 - val_accuracy: 0.6667\n",
            "Epoch 475/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0302 - accuracy: 0.6190 - val_loss: 0.0629 - val_accuracy: 0.6667\n",
            "Epoch 476/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0302 - accuracy: 0.6190 - val_loss: 0.0623 - val_accuracy: 0.6667\n",
            "Epoch 477/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0299 - accuracy: 0.6190 - val_loss: 0.0623 - val_accuracy: 0.6667\n",
            "Epoch 478/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0299 - accuracy: 0.6190 - val_loss: 0.0621 - val_accuracy: 0.6667\n",
            "Epoch 479/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0299 - accuracy: 0.6190 - val_loss: 0.0627 - val_accuracy: 0.6825\n",
            "Epoch 480/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.6190 - val_loss: 0.0623 - val_accuracy: 0.6825\n",
            "Epoch 481/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0300 - accuracy: 0.6190 - val_loss: 0.0624 - val_accuracy: 0.6825\n",
            "Epoch 482/500\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0298 - accuracy: 0.6190 - val_loss: 0.0624 - val_accuracy: 0.6825\n",
            "Epoch 483/500\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0304 - accuracy: 0.6190 - val_loss: 0.0628 - val_accuracy: 0.6667\n",
            "Epoch 484/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0298 - accuracy: 0.6190 - val_loss: 0.0625 - val_accuracy: 0.6667\n",
            "Epoch 485/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0300 - accuracy: 0.6190 - val_loss: 0.0625 - val_accuracy: 0.6667\n",
            "Epoch 486/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0297 - accuracy: 0.6190 - val_loss: 0.0626 - val_accuracy: 0.6667\n",
            "Epoch 487/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0297 - accuracy: 0.6190 - val_loss: 0.0623 - val_accuracy: 0.6825\n",
            "Epoch 488/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0306 - accuracy: 0.6190 - val_loss: 0.0623 - val_accuracy: 0.6825\n",
            "Epoch 489/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0298 - accuracy: 0.6190 - val_loss: 0.0621 - val_accuracy: 0.6825\n",
            "Epoch 490/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0298 - accuracy: 0.6190 - val_loss: 0.0619 - val_accuracy: 0.6825\n",
            "Epoch 491/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0294 - accuracy: 0.6190 - val_loss: 0.0619 - val_accuracy: 0.6825\n",
            "Epoch 492/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0293 - accuracy: 0.6190 - val_loss: 0.0620 - val_accuracy: 0.6667\n",
            "Epoch 493/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0295 - accuracy: 0.6190 - val_loss: 0.0623 - val_accuracy: 0.6667\n",
            "Epoch 494/500\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0295 - accuracy: 0.6190 - val_loss: 0.0624 - val_accuracy: 0.6667\n",
            "Epoch 495/500\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0295 - accuracy: 0.6190 - val_loss: 0.0624 - val_accuracy: 0.6825\n",
            "Epoch 496/500\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0296 - accuracy: 0.6190 - val_loss: 0.0619 - val_accuracy: 0.6825\n",
            "Epoch 497/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0294 - accuracy: 0.6190 - val_loss: 0.0616 - val_accuracy: 0.6825\n",
            "Epoch 498/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0293 - accuracy: 0.6190 - val_loss: 0.0617 - val_accuracy: 0.6825\n",
            "Epoch 499/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0292 - accuracy: 0.6190 - val_loss: 0.0616 - val_accuracy: 0.6825\n",
            "Epoch 500/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0296 - accuracy: 0.6190 - val_loss: 0.0616 - val_accuracy: 0.6825\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train, train_labels, epochs=500, batch_size=32, validation_data=(test, test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwLOi7Wo_CFU",
        "outputId": "1951f6f1-152e-408f-b071-269dcf064c10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0616 - accuracy: 0.6825\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.061587855219841, 0.682539701461792]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predicción\n",
        "\n",
        "Aquí se puede ver que los datos de predicción se dividen en tres zonas, una cerca de 1, otra cerca de 0.5 y otra cerca de 0. Esto ya que los datos fueron normalizados anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "2fXpv-0f_QZG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 8ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(test)\n",
        "predictions = pd.DataFrame(predictions)\n",
        "predictions.columns = [\"Predictions\"]\n",
        "predictions[\"Target\"] = test_labels\n",
        "sorted_predictions = predictions.sort_values([\"Predictions\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En la gráfica se puede ver que la predicción es muy buena, ya que la mayoría de los datos se encuentran cerca de 1, 0.5 o 0. Pero también se puede apreciar valores que no están en ninguna de las zonas, lo que significa que la predicción no es perfecta, y comprobamos el 70% de precisión que nos dio el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "IJIfj7sTAbyb",
        "outputId": "588de30a-0a16-4dc3-9b17-ad9a9a1012c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x23c626a1640>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(np.sort(sorted_predictions[\"Predictions\"]), \".\", label=\"Prediction\")\n",
        "plt.plot(np.sort(sorted_predictions[\"Target\"]), \".\", label=\"Target\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gráficas de error y precisión\n",
        "\n",
        "Algo que se puede ver es que esta arquitectura da un error mucho menor que la arquitectura anterior, lo que significa que el modelo se está entrenando mejor. Pero también se puede ver que la precisión es menor, lo que significa que el modelo no está aprendiendo tan bien."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "RTl4728w-prz",
        "outputId": "340b25c2-3bcb-44c5-dfd5-9b0213cbc736"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x23c626a6730>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.subplot(211)\n",
        "plt.title('Loss')\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "sKW6KurB-3CE",
        "outputId": "e5ea4544-9813-4cc4-909b-fa1b6e7e4f16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x23c627787c0>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.subplot(212)\n",
        "plt.title('Accuracy')\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='test')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusiones\n",
        "\n",
        "Con este ejercicio se ver que la arquitectura de la red neuronal es muy importante para el modelo. Una capa más, una capa menos, una neurona más o una neurona menos, puede hacer que el modelo se entrene mejor o peor. También se puede ver que la función de activación es muy importante, ya que si se usa una función de activación incorrecta, el modelo no se entrenará correctamente.\n",
        "\n",
        "Podemos reconocer que la aplicación de las redes neuronales ayudará mucho en el futuro, encontrando aplicación en muchos aspectos de la vida humana, dada su narualeza de aprendizaje. Pero esperamos que se siga investigando para que se pueda encontrar un método para definir cuántas capas y neuronas se deben usar en cada red neuronal, ya que en este ejercicio se tuvo que probar varias veces para encontrar la arquitectura que mejor se ajustaba a los datos.\n",
        "\n",
        "Seguiremos experimentando con esta poderosa herramienta en diferentes proyectos, para seguir aprendiendo y mejorando nuestras habilidades.\n",
        "\n",
        "## Observaciones y recomendaciones\n",
        "\n",
        "- Se recomienda usar una función de activación `relu` en la capa de entrada, ya que esta función es la que mejor funciona en la mayoría de los casos.\n",
        "\n",
        "- Se recomienda usar una función de activación `softmax` en la capa de salida si la salida es puede ser una de varias categorías.\n",
        "\n",
        "- El hecho que el error sea muy bajo no significa que el modelo esté entrenado correctamente. Esto se puede ver en la gráfica de precisión, donde se puede ver que la precisión es muy baja. Esto afecta directamente la precisión del modelo. Y si el modelo no predice correctamente, no sirve para nada.\n",
        "\n",
        "- Se pudo observar que colocar más capas a la red, no necesariamente significa que el modelo se entrenará mejor.\n",
        "\n",
        "- Comparando los ejercicios anteriores, ya que la salida del conjunto de datos es categórica, se recomienda dividir los datos en 3 categorías. Esto dará mejores resultados de precisión.\n",
        "\n",
        "- No descuidar el procesamiento previo de datos, que consideramos que es la parte más tediosa del ejercicio. Dependiendo de cómo se procesen los datos, la arquitectura cambiará. Esto se pudo evidenciar cuando se procesaron los datos para una salida de 3 neuronas se usó una función de activación y una función de pérdida diferentes a las que se usaron para una salida de una sola neurona."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b2a747836dbd3d24a41a2e0f1be3b2e08d73c43f6ab8cf54c59a433ce2434b74"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
